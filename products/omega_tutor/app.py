"""
OMEGA Tutor â€” Streamlit chat interface.
Ask anything. Learn at your level. Zero friction.
"""

import sys
from pathlib import Path

_ROOT = Path(__file__).resolve().parent
if str(_ROOT) not in sys.path:
    sys.path.insert(0, str(_ROOT))

# Load .env from project root so GEMINI_API_KEY / ANTHROPIC_API_KEY are available
import os
try:
    from dotenv import load_dotenv
    load_dotenv(_ROOT / ".env")
except ImportError:
    pass

import streamlit as st
from core import TutorEngine

st.set_page_config(page_title="OMEGA Tutor", page_icon="ğŸ“", layout="wide")

st.title("ğŸ“ OMEGA Tutor")
st.caption("Ask anything. Learn at your level.")

# Level selector in sidebar
level = st.sidebar.selectbox(
    "Learning Level",
    ["child", "teen", "adult", "expert", "researcher"],
    index=2,
    format_func=lambda x: {
        "child": "ğŸ‘¶ Child (5-10)",
        "teen": "ğŸ® Teen (11-17)",
        "adult": "ğŸ‘¤ Adult",
        "expert": "ğŸ“ Expert",
        "researcher": "ğŸ”¬ Researcher",
    }[x],
)

st.sidebar.markdown("---")
st.sidebar.markdown("""
**Levels explained:**
- **Child**: Simple words, fun examples
- **Teen**: Real-world connections
- **Adult**: Clear and practical
- **Expert**: Nuance and depth
- **Researcher**: Full OMEGA-MAX analysis
""")

# API key: env (or .env) or sidebar
env_has_key = bool(os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY") or os.environ.get("ANTHROPIC_API_KEY"))
if env_has_key:
    st.sidebar.caption("Using API key from environment (.env or shell)")
api_key = st.sidebar.text_input(
    "API key (optional)",
    type="password",
    placeholder="Paste here if not using .env",
    help="Or put GEMINI_API_KEY=... in omega_tutor/.env so it works from any terminal.",
)
if not env_has_key and not api_key:
    st.sidebar.caption("No key set. Add omega_tutor/.env with GEMINI_API_KEY=... or paste above.")

# Backend: LM Studio (local) or Gemini (cloud)
try:
    _engine = TutorEngine(api_key=api_key or None)
    backend_label = "ğŸ–¥ï¸ Local (LM Studio)" if _engine.use_local else "â˜ï¸ Cloud (Gemini)"
except Exception:
    _engine = None
    backend_label = "âš ï¸ No backend (start LM Studio or set GEMINI_API_KEY)"
st.sidebar.caption(backend_label)

# Chat interface
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input
if prompt := st.chat_input("What would you like to learn about?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            engine = _engine if _engine is not None else TutorEngine(api_key=api_key or None)
            response = engine.teach(prompt, level=level)
            st.markdown(response.to_markdown())

    st.session_state.messages.append({"role": "assistant", "content": response.to_markdown()})

# Quick actions
st.sidebar.markdown("---")
if st.sidebar.button("ğŸ”„ New Topic"):
    st.session_state.messages = []
    st.rerun()

if st.sidebar.button("ğŸ“š Go Deeper") and st.session_state.messages:
    user_msgs = [m for m in st.session_state.messages if m["role"] == "user"]
    if user_msgs:
        last_topic = user_msgs[-1]["content"]
        engine = _engine if _engine is not None else TutorEngine(api_key=api_key or None)
        response = engine.deeper(last_topic, level)
        st.session_state.messages.append({"role": "assistant", "content": response.to_markdown()})
    st.rerun()
